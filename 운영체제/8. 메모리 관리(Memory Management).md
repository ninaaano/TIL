# 8. 메모리 관리(Memory Management)

메모리란 주소를 통해 접근하는 객체로 메인 메모리는 주 기억장치를 의미한다.

## Logical / Physical Address

### 논리 주소 (Logical address) = virtual address

- 프로세스마다 독립적으로 가지는 주소공간
- 각 프로세스마다 0번지부터 시작
- CPU가 보는 주소는 logical address임

이 주소는 CPU가 인식하는 주소 체계이다.

### 물리 주소 (Physical address)

- 메모리에 실제 올라가는 위치

실제 하드웨어에 올라가는 위치를 뜻한다

### symbolic address

프로그래머들이 특정 이름을 통해 변수를 지정하고 값을 저장할 때, 

그 변수를 하드웨어의 몇 번지에 저장할 지 정하지 않고, 그 변수를 CPU가 어떻게 인식할지도 정하지 않는다

그저 변수의 이름을 통해서 그 값에 접근할 수 있다.

그 변수를 symbolic address라고 한다. 이 주소가 컴파일되어 숫자 주소가 만들어지고 이것이 물리적인 메모리와 매핑된다. 이를 주소 바인딩이라고 한다

## 주소바인딩(Address Binding)

데이터의 주소를 결정 하는 것

어떤 프로그램이 물리적인 메모리에서 어느 부분에 적재될 지 결정하는 것

- Symbolic Address → Logical address →(이 시점이 언제인가? next page) Physical address

### Compile time binding

- 물리적 메모리 주소(Physical address)가 컴파일 시 알려짐
- 시작 위치 변경 시 재컴파일
- 컴파일러는 절대 코드(absolute code)생성
- 지금은 사용하지 않음

### Load time binding

- Loader의 책임 하에 물리적 메모리 주소 부여
- 컴파일러가 재배치가능 코드(relocatable code)를 생성한 경우 가능
- 프로그램이 시작되서 메모리에 올라갈때 물리적인 메모리 주소 결정

### Execution time binding(=Run time binding)

- 수행이 시작된 이후에도 프로세스의 메모리 상 위치를 옮길 수 있음
- CPU가 주소를 참조할 때마다 binding을 점검(address mapping table)
- 하드웨어 적인 지원이 필요 (e.g. , base and limit registers, MMU)
- 실행 시에 주소가 변경되고 바뀔 수 있음
- 현재 우리의 컴퓨터에서 사용됨


## Memory-Management Unit(MMU)

가상 메모리 주소를 실제 물리적인 메모리 주소로 변환하는 역할. 운영체제에서 프로세스가 사용하는 가상 메모리 주소 공간을 물리적인 메모리 주소 공간에 매핑하는 것을 가능하게 한다

메모리 보호, 주소 변환 및 가상 메모리 관리와 같은 역할을 담당한다

### MMU (Memory-Management Unit)

- logical address를 physical address로 매핑해주는 Hardware device

### MMU scheme

- 사용자 프로세스가 CPU에서 수행되며 생성해내는 모든 주소 값에 대해 base register (=relocation register)의 값을 더한다

### user program

- logical address만을 다룬다
- 실제 physical address를 볼 수 없으며 알 필요가 없다

### 동적 메모리 재배치 (Dynamic Relocation)

컴퓨터 프로그램의 실행 시에 메모리 주소를 재배치하여 프로그램이 실제로 사용하는 메모리 주소에 해당하는 위치에 코드와 데이터를 로드하는 기술을 말한다. 이 기술은 프로그램이 실행되는 동안 메모리의 일부 영역이 사용되고 해제되는 경우에 유용하다.

일반적으로 프로그램은 컴파일러를 통해 소스 코드에서 기계어 코드로 변환된다, 이 때 기계어 코드는 메모리 주소에 의존하는 경우가 많은데, 변수는 메모리 주소에 할당되고, 프로그램의 다른 부분에서 해당 변수를 참조할 때 이 주소를 사용한다

그러나 프로그램이 실행될 때마다 메모리에 할당되는 위치는 다를 수 있다. 이는 운영 체제가 프로그램의 메모리 요구 사항을 충족하기 위해 사용 가능한 메모리 주소를 동적으로 선택하기 때문이다. 이 때문에 프로그램이 정확한 메모리 주소를 참조 할 수 없을 수 있다.

이를 해결하기 위해 Dynamic Relocation기술이 사용된다. 

MMU는 relocation register와 limit register를 사용하여 가상 메모리 주소를 물리적인 메모리 주소로 변환한다. 

- relocation register(= base register) : 접근할 수 있는 물리적 메모리 주소의 최솟값. 가상 주소 공간을 물리 주소 공간으로 변환하는 데 사용된다.
- Limit register : 논리적 주소의 범위. 프로세스가 접근할 수 있는 메모리 영역을 제한하는데 사용된다. 프로세스가 가상 주소를 사용하여 메모리에 엑세스하면, MMU는 해당 주소가 limit register의 범위 내에 있는지 확인하고, 범위를 벗어나는 경우 MMU는 해당 주소에 액세스하는 것을 거부한다

### Hardware Support for Address Translation

운영체제 및 사용자 프로세스 간의 메모리 보호를 위해 사용하는 레지스터

### Dynamic Loading

- 프로세스 전체를 메모리에 미리 다 올리는 것이 아니라 해당 루틴이 불려질 때 메모리에 load하는 것
- memory utilzation의 향상
- 가끔씩 사용되는 많은 양의 코드의 경우 유용하다 (ex: 오류 처리 루틴)
- 운영체제의 특별한 지원 없이 프로그램 자체에서 구현 가능(OS는 라이브러리를 통해 지원 가능)

`Loading` : 메모리로 올리는 것

1. 프로그램 실행 시 필요한 라이브러리나 함수를 로드하지 않고 프로그램에서 사용하는 함수의 이름만을 참조한다
2. 프로그램이 실행 중일 때 해당 함수를 호출하면 운영 체제는 해당 함수나 라이버르러리를 메모리에 로드한다
3. 함수가 로드되면, 프로그램은 해당 함수를 호출할 수 있다

동적 로딩 방식을 사용하면, 프로그램의 실행 속도를 향상시킬 수 있다. 또한, 모든 함수나 라이브러리를 한 번에 로드하지 않으므로 메모리 사용량을 줄일 수 있다. 동적 로딩은 대규모 프로그램의 성능과 안정성을 향상시키는데 유용하다.

단점은 , 라이브러리나 함수가 로드되기 전에 해당 함수를 호출하면, 런타임 오류가 발생할 수 있다. 이를 방지하기 위해 프로그램에서 함수를 호출하기 전에 해당 함수가 로드되어 있는지 확인하는 코드를 추가해야한다

### Overlays

- 메모리에 프로세스의 부분 중 실제 필요한 정보만을 올림
- 프로세스의 크기가 메모리보다 클 때 유용
- 운영체제의 지원 없이 사용자에 의해 구현
- 작은 공간의 메모리를 사용하던 초창기 시스템에서 수작업으로 프로그래머가 구현
    - “Manual Overlay”
    - 프로그래밍이 매우 복잡

### 동적 로딩과 오버레이의 차이점

1. 사용하는 시점의 차이점
- 동적 로딩 : 프로그램이 실행 중일 때 필요한 라이브러리나 함수를 로드
- 오버레이 : 프로그램이 실행될 때 필요한 일부 코드와 데이터만 메모리에 로드
1. 대상의 차이점
- 동적 로딩 : 라이브러리와 함수 등의 실행 코드
- 오버레이 : 프로그램 코드, 데이터
1. 동작 방식의 차이점
- 동적 로딩 : 필요한 함수를 호출할 때마다 런타임에 해당 함수를 로드하여 실행
- 오버레이 :  프로그램이 실행 될 때, 필요한 일부 코드와 데이터만을 메모리에 로드하며, 필요하지 않은 코드는 하드 디스크에 저장

동적 로딩 - 실행 중인 프로그램에 필요한 함수나 라이브러리를 필요할 때마다 메모리에 로드하여 사용하는 방법

오버레이 - 대부분의 메모리를 차지하는 코드나 데이터를 세그먼트 단위로 분할하여, 실행 시점에 필요한 일부만 메모리에 로등하는 방법.  작은 메모리에서 대규모 프로그램 실행할 수 있다

동적 로딩과 오버레이는 모두 메모리 사용량을 최적화하는 방법이다. 그러나 오버레이는 프로그램 전체를 한 번에 로드하지 않으므로, 프로그램의 실행 속도를 떨어트릴 수 있다. 동적 로딩은 필요한 함수를 필요할 때마다 로드하므로 프로그램의 실행 속도를 유지할 수 있다

### Swapping

- `swapping`
    - 프로세스를 일시적으로 메모리에서 backing store로 쫓아내는 것
- `Backing store(=swap area)`
    - 디스크
        - 많은 사용자의 프로세스 이미지를 담을 만큼 충분히 빠르고 큰 저장 공간
- `Swap in / Swap out`
    - 일반적으로 중기 스케줄러(swapper)에 의해 swap out 시킬 프로세스 선정
    - priority-based CPU scheduling algorithm
        - priority가 낮은 프로세스를 swapped out 시킴
        - priority가 높은 프로세스를 메모리에 올려 놓음
    - Compile time 혹은 load time binding에서는 원래 메모리 위치로 swap in해야 함
    - Execution time binding에서는 추후 빈 메모리 영역 아무 곳에나 올릴 수 있음
    - swap time은 대부분 transfer time(swap되는 양에 비례하는 시간)임

### Dynamic Linking

- Linking을 실행시간(execution time)까지 미루는 기법
- Static linking
    - 라이브러리가 프로그램의 실행 파일 코드에 포함됨
    - 실행 파일의 크기가 커짐
    - 동일한 라이브러리를 각각의 프로세스가 메모리에 올리므로 메모리 낭비(eg. printf 함수의 라이브러리 코드)
- Dynamic linking
    - 라이브러리가 실행 시 연결(link)됨
    - 라이브러리 호출 부분에 라이브러리 루틴의 위치를 찾기 위한 stub이라는 작은 코드를 둠
    - 라이브러리가 이미 메모리에 있으면 그 루틴의 주소로 가고, 없으면 디스크에서 읽어옴
    - 운영체제의 도움이 필요

## 물리적 메모리를 어떻게 관리 할 것인가?

### Allocation of Physical Memory

- 메모리는 일반적으로 두 영역으로 나뉘어 사용

- OS 상주 영역
    - interrupt vector와 함께 낮은 주소 영역 사용
- 사용자 프로세스 영역
    - 높은 주소 영역 사용
- 사용자 프로세스 영역의 할당 방법
    - 연속 할당 (Contiguous allocation)
    : 각각의 프로세스가 메모리의 연속적인 공간에 적재되도록 하는 것
        - Fixed partition allocation
        - Variable partiton allocation
    - 비연속 할당 (Noncontiguous allocation)
    : 하나의 프로세스가 메모리의 여러 영역에 분산되어 올라갈 수 있음
        - Paging
        - Segmentation
        - Paged Segmentation

### Contiguous Allocation

- 고정분할(Fixed partition) 방식
    - 물리적 메모리를 몇 개의 영구적 분할(partition)로 나눔
    - 분할의 크기가 모두 동일한 방식과 서로 다른 방식이 존재
    - 분할당 하나의 프로그램 적재
    - 융통성이 없음
        - 동시에 메모리에 Load되는 프로그램의 수가 고정됨
        - 최대 수행 가능 프로그램 크기 제한
    - Internal fragmentation 발생 (external fragmentation도 발생)
- 가변분할(Variable partition) 방식
    - 프로그램의 크기를 고려해서 할당
    - 분할의 크기, 개수가 동적으로 변함
    - 기술적 관리 기법 필요
    - External fragmentation 발생
- Hole
    - 가용 메모리 공간
    - 다양한 크기의 hole들이 메모리 여러 곳에 흩어져 있음
    - 프로세스가 도착하면 수용가능한 hole을 할당
    - 운영체제는 다음의 정보를 유지
        - a) 할당 공간 b) 가용 공간 (hole)

`Dynamic Storage-Allocation Problem`

: 가변 분할 방식에서 size n인 요청을 만족하는 가장 적절한 hole을 찾는 문제

- First-fit
    - Size가 n 이상인 것 중 최초로 찾아지는 hole에 할당
- Best-fit
    - Size가 n 이상인 가장 작은 hole을 찾아서 할당
    - Hole들의 리스트가 크기순으로 정렬되지 않은 경우 모든 hole의 리스트를 탐색해야함
    - 많은 수의 아주 작은 hole들이 생성됨
- Worst-fit
    - 가장 큰 hole에 할당
    - 역시 모든 리스트를 탐색해야 함
    - 상대적으로 아주 큰 hole들이 생성됨
- First-fit과 best-fit이 worst-fit보다 속도와 공간 이용률 측면에서 효과적인 것으로 알려짐
- compaction
    - external fragmentation 문제를 해결하는 한 가지 방법
    - 사용 중인 메모리 영역을 한 군데로 몰고 hole들을 다른 한 곳으로 몰아 큰 block을 만드는 것
    - 매우 비용이 많이 드는 방법
    - 최소한의 메모리 이동으로 compaction하는 방법(매우 복잡한 문제)
    - Compaction은 프로세스의 주소가 실행 시간에 동적으로 재배치 가능한 경우에만 수행될 수 있다

### Paging

- Paging
    - Process의 virtual memory를 동일한 사이즈의 Page 단위로 나눔
    - Virtual memory의 내용이 page 단위로 noncontiguous하게 저장됨
    - 일부는 backing storage에, 일부는 physical memory에 저장
- Basic Method
    - physical memory를 동일한 크기의 frame으로 나눔
    - logical memory를 동일 크기의 page로 나눔(frame과 같은 크기)
    - 모든 가용 frame들을 관리
    - page table을 사용하여 logical address를 physical address로 변환
    - External fragmentation 발생 안함
    - Internal fragmentation 발생 가능

### 페이지 테이블 구현 (Implementation of Page Table)

- page table은 main memory에 상주
- Page-table base register (PTBR) 가 page tabel을 가리킴
- Page-table length register (PTLR) 가 테이블 크기를 보관
- 모든 메모리 접근 연산에는 2번의 memory access 필요
- page tabel 접근 1번, 실제 data/instruction 접근 1번
- 속도 향상을 위해 associative register 혹은 translation look-aside buffer (TLB) 라 불리는 고속의 lookup hardware cache 사용

기본적인 레지스터 두개가 페이징 기법에선 PTBR과 PTLR로 사용된다.
TLB는 메인 메모리와 CPU 사이에 존재하는 주소 변환을 위한 계층이다. (메인 메모리보다 빠르다)
주소 변환을 위한 캐시 메모리이다. 빈번이 참조되는 일부 엔트리를 캐싱하고 있다.
메인 메모리보다 접근 속도가 빠른 하드웨어로 구성되어 있다
메모리 상에 있는 페이지 테이블을 접근하기 전에 TLB를 먼저 검색해본다
혹시 주소 변환 정보 중에서 TLB에 저장되어있는 정보를 이용해서 주소 변환이 가능한지 확인해본다
페이지 테이블로 가기 전에 TLB에 이미 저장이 되있다면 TLB를 통해 바로 주소 변환이 이뤄진다. 그럼 바로 주소변환을 해서 물리 메모리로 접근하기 때문에 메모리를 1번만 접근하면 된다
없는 경우엔 페이지 테이블을 통해 일반적인 주소변환을 하고 메모리에 접근하기 때문에 2번의 접근이 필요하다
TLB는 전체를 담지 않고 일부만 담고있다. (빈번하게 참조되는)

## Associative register

- associative register (TLB) : TLB는 보통 Associative register를 이용해서 구현하고 있다. (병렬 검색 가능)
가상 메모리 주소를 물리적인 주소로 변환하는 속도를 높이기 위해 사용되는 캐시
최근에 일어난 가상 메모리 주소와 물리 주소의 변환 테이블 저장
일종의 주소 변환 캐시

- Address translation
    - page table 중 일부가 associative register에 보관되어 있다
    - 만약 해당 page #(num)이 associative register에 있는 경우 곧바로 frame #을 얻는다
    - 그렇지 않은 경우 메인 메모리에 있는 페이지 테이블로부터 frame #을 얻는다
    - TLB는 컨텍스트 스위치 때 flush (remove old entries)

## 메모리에 접근하는 시간

TLB에 접근하는 시간이 e(엡실론)이라고 할 때 접근하는 시간이 메인 메모리에 접근하는 시간인 1보다 작다
TLB로부터 주소 변환이 되는 비율을 알파라고 했을 때 실제로 메모리에 접근하는 시간을 계산하면

2보다는 훨씬 작은 값이 된다 (어떻게 계산하는지 잘 모르겠다..)

# Two-Level Page Table (2단계 페이지 테이블)

page table을 위한 공간을 줄이기 위해 사용. 속도는 줄어들지 않는다
현대의 컴퓨터는 address space가 매우 큰 프로그램을 지원한다

- 32 bit address 사용시 : 2^32(4G)의 주소 공간
    - page size가 4K시 1M개의 page table entry가 필요하다
    - 각 page entry가 4B시 프로세스 당 4M의 page table이 필요하다
    - 그러나 대부분의 프로그램은 4G의 주소 공간 중 지극히 일부분만 사용하므로 page table 공간이 심하게 낭비된다
- > page table 자체를 page로 구성
-> 사용되지 않는 주소 공간에 대한 outer page table의 엔트리 값은 NULL(대응하는 inner page table이 없음)

2단계 페이징 테이블 기법에서는 바깥 페이지 테이블은 전체 논리적 메모리 크기만큼 만들어지지만, 실제로 사용하지 않는 주소에 대해서는 안쪽 페이지 테이블을 만들어두지 않고 null로 남겨둔다.
그럼 이걸 왜 사용하느냐? 페이지 테이블의 공간을 줄일 수 있기 때문인데, 어떻게 줄이느냐?
전체 주소 공간 중 상당 부분이 실제로 사용이 안되는 공간이기 때문에(그래서 안쪽 페이지 테이블이 만들어지지 않기 때문에) 그런것이다

# Multilevel Paging and Performance (다단계 페이지 테이블)

- Address space가 더 커지면 다단계 페이지 테이블이 필요하다
- 각 단계의 페이지 테이블이 메모리에 존재하므로 logical address의 physical address 변환에 더 많은 메모리 접근이 필요하다
- TLB를 통해 메모리 접근 시간을 줄일 수 있다
- 4단계 페이지 테이블을 사용하는 경우
    - 메모리 접근 시간이 100ns, TLB 접근 시간이 20ns이고
    - TLB hiy ratio가 98%인 경우 effective memory access time = 0.98 * 120 + 0.02 * 520 = 128 ns
    결과적으로 주소 변환을 위해 28ns만 소요된다

페이지 테이블에 주소변환정보만 들어있는 것이 아니고 부가적인 비트가 엔트리마다 같이 저장된다

### Memory Protection

Page table의 각 엔트리마다 아래의 bit를 둔다

- Protection bit
    - 페이지에 대한 접근 권한(read/write/read-only)
    - 연산에 대한 권한을 표시하기 위한 비트
- valid-invalid bit
valid라는 것은 실제로 물리적인 메모리에 올라와 있다는 것이고 invalid는 이 페이지가 프로그램에서 사용되지 않거나 페이지가 메모리에 당장 올라가지 않을 수도 있다.
    - valid : 해당 주소의 프레임에 그 프로세스를 구성하는 유효한 내용이 있음을 뜻함 (접근 허용)
    - invalid : 해당 주소의 프레임에 유효한 내용이 없을 뜻함 (접근 불허)
        - 프로세스가 그 주소 부분을 사용하지 않는 경우
        - 해당 페이지가 메모리에 올라와 있지 않고 swap 영역에 있는 경우

## Inverted Page Table

페이지 테이블의 문제는 굉장히 많은 용량을 차지하고 있다는 것이다. 주소 공간이 허용하는 한도 만큼 페이지 테이블이 만들어져야 하고 또 프로세스마다 각각 주소 변환을 해야하기 때문에 각 프로세스 별로 페이지 테이블이 만들어져야하기 때문에 굉장히 공간 오버헤드가 컸다. 그걸 막아보기위해 나온 것이 Inverted Page Table이다

- Page table이 매우 큰 이유
    - 모든 프로세스 별로 그 논리적 주소에 대응하는 모든 페이지에 대해 페이지 테이블 엔트리가 존재
    - 대응하는 페이지가 메모리에 있든 아니든 간에 페이지 테이블에는 엔트리로 존대
- Inverted page table
    - 페이지 프레임 하나 당 페이지 테이블에 하나의 엔트리를 둔 것 (system-wide)
    - 각 페이지 테이블 엔트리는 각각의 물리적 메모리 페이지 프레임이 담고 있는 내용 표시 (프로세스 id, 프로세스의 논리 주소)
    - 장점 : 페이지 테이블을 위한 공간을 줄인다
    - 단점 : 테이블 전체를 탐색해야 함. 시간적인 오버헤드가 존재한다
    - 조치 : associative register 사용 (비쌈)

원래의 페이지 테이블을 통한 주소 변환을 완전히 역발상으로 뒤집어 놓은 것이다.

시스템 안에 페이지 테이블이 각 프로세스마다 존재하는 것이 아닌, 단 하나 존재한다. 

페이지 테이블의 엔트리가 물리적 메모리의 페이지 프레임 개수만큼 존재한다. 

우리가 주소 변환을 하려면 논리 주소에서 페이지 번호를 보고 페이지 테이블에서 번호만큼 떨어진 엔트리에 가서 주소 변환을 하는 방법을 사용했는데, Inverted Page Table은 그것이 불가능하다. 이유는 정방향으로 주소 변환을 하는 것이 아닌 페이지 프레임의 논리적인 번호가 나오게 되어있다. 주소 변환은 논리 주소를 물리 주소로 바꾸는 것이지 이것은 물리 주소를 보고 논리 주소로 바꿀 수 있는 테이블이다. 우리 목적에 맞지 않는 테이블인데, 논리 주소에 해당하는 페이지 번호 p가 물리적 메모리의 어디에 올라가 있는지를 찾으려면 페이지 테이블 엔트리를 다 찾아봐야한다. 

# Shared Page (공유 페이지)

페이징 기법의 장점 중 하나는 코드를 공유할 수 있는 가능성이다. 

공유페이지를 하기 위해선 재진입가능 코드여야 하며, 읽기 전용 특성을 코드에게만 의존하는 것이 아니라 운영체제가 이 속성을 강제해야한다

- Shared code
    - Re-entrant Code (=Pure Code) 재진입가능 코드, 실행 중에 변하지 않는 코드
        - 따라서 둘 이상의 프로세스가 동시에 같은 코드를 실행할 수 있다. 즉, 각 프로세스는 동일한 코드를 서로 다른 데이터로 실행한다
    - read-only로 하여 프로세스 간에 하나의 코드만 메모리에 올림 (eg, text editors, compilers, windows systems)
    - Shared code는 모드 프로세스의 논리 주소 공간에서 동일한 위치에 있어야 한다
- Private code and data
    - 각 프로세스들은 독자적으로 메모리에 올림
    - Private data는 논리 주소 공간의 아무 곳에 와도 무방

# Segmentation

프로그램은 의미 단위인 여러개의 세그먼트로 구성되어 있다.

- 작게는 프로그램을 구성하는 함수 하나하나를 세그먼트로 정의
- 크게는 프로그램 전체를 하나의 세그먼트로 정의 가능
- 일반적으로는 code, data, stack 부분이 하나씩의 세그먼트로 정의됨
- 논리주소는 segment-number와 offset으로 구성되어 있다

## Segment table

- base - starting physical address of the segment. 물리 주소에서의 세그먼트의 시작 위치
- limit - length of the segment. 물리주소에서의 세그먼트의 길이

### Segment-table base register (STBR)

물리적 메모리에서의 세그먼트 테이블의 위치

### Segment-table length register (STLR)

프로그램이 사용하는 세그먼트의 수. 논리주소의 세그먼트 번호가 STLR보다 작아야한다. 크다면 트랩에 걸린다

테이블을 위한 메모리 낭비가 심한건 세그멘테이션보단 페이징이다

세그멘테이션은 의미 단위로 해야 의미가 있다? 무슨 소리일까..

공유 세그먼트, 프라이빗 세그먼트가 따로 있는 것 같다

# Paged Segmentation

페이징 + 세그멘테이션

세그먼트를 여러개의 페이지로 구성하는 것이다

- pure segmentation과의 차이점
    - 세그먼트 테이블 엔트리가 세그먼트의 베이스 주소를 가지고 있는 것이 아니라 세그먼트를 구성하는 페이지 테이블의 베이스 주소를 가지고 있다

Allocation 문제가 발생하지 않음

세그먼트 테이블에 세그먼트 길이와 페이지 테이블 베이스가 있다

세그먼트 길이와 논리적 주소의 오프셋 비교하고

오프셋을 또 잘라서 앞부분은 페이지 번호, 뒷 부분은 페이지 안에서 얼마나 떨어져 있는지 

여태까지 물리적 메모리에서의 메모리 관리를 설명하였다.

여기서 운영체제의 역할을 뭐였을까?

주소변환이다. 어떤 프로세스가 논리적인 주소를 가지고 있고 CPU가 논리적인 주소를 주면 그걸 물리적인 메모리로 변환해서 메모리 참조를 하는 것이 이 챕터의 주제였다.

주소 변환에서 운영체제의 역할이 뭐였을까요? 사실 이 챕터에선 없었다. 이런건 하드웨어가 해줘야할 일이다(MMU). 왜그러냐면 어떤 프로세스가 CPU를 가지고 있으면서 메모리 접근을 하는거면 운영체제의 도움을 받을까? 전혀 받지 않는다. 주소 변환을 할때마다 운영체제의 도움이 필요하다면 말이 안되는 것이다. 운영체제는 IO장치를 접근할 때 사용한다. 사용자 프로세스가 직접 접근 할 수 없기 때문이다